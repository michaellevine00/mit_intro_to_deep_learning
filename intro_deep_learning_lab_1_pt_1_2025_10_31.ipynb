{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62dc9dd9-cd88-4579-9bd6-f559e381d736",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Notebook link\n",
    "Notebook link: https://github.com/MITDeepLearning/introtodeeplearning/blob/master/lab1/PT_Part1_Intro.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6dda6e2-9347-4078-a204-79a6774b8650",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Creating 1-d Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beb72fa7-3e48-4522-ab55-529bbd208f7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04ed4d6e-502f-47c6-beb9-92eabe96aa29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "PyTorch provides an interface for creating and manipulating tensors, which are data structures that you can think of as multi-dimensional arrays. Tensors are represented as n-dimensional arrays of base datatypes such as a string or integer -- they provide a way to generalize vectors and matrices to higher dimensions. PyTorch provides the ability to perform computation on these tensors, define neural networks, and train them efficiently.\n",
    "\n",
    "The shape of a PyTorch tensor defines its number of dimensions and the size of each dimension. The ndim or dim of a PyTorch tensor provides the number of dimensions (n-dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eddd6fb2-796a-4266-8fc4-2b893483db49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num is tensor([-7.0700e-28,  4.5615e-41, -7.0700e-28,  4.5615e-41,  5.3249e-43,\n",
      "         0.0000e+00,  4.8231e+28, -5.5506e-02,  1.3868e-38,  5.2128e-43,\n",
      "         0.0000e+00,  0.0000e+00,  6.0979e-38,  6.2815e-38,  0.0000e+00,\n",
      "         0.0000e+00, -1.9629e-13,  8.4638e-43,  1.8588e-37,  4.2981e-38,\n",
      "         0.0000e+00,  0.0000e+00,  4.6290e-38,  3.5032e-44,  0.0000e+00,\n",
      "         6.9060e-37,  0.0000e+00,  4.1905e-38,  1.4235e-38,  1.8515e-37,\n",
      "         5.0727e-43,  0.0000e+00,  1.4235e-38,  5.1539e-35,  2.2964e-39,\n",
      "         0.0000e+00,  0.0000e+00,  2.6802e-36,  7.4359e-37,  1.9562e-42,\n",
      "         0.0000e+00,  0.0000e+00,  6.0984e-38,  6.2815e-38,  0.0000e+00,\n",
      "         0.0000e+00,  1.8514e-37,  1.2247e-42,  0.0000e+00,  3.2209e-36,\n",
      "         2.2964e-39,  0.0000e+00,  0.0000e+00,  1.2261e-42,  8.3961e-16,\n",
      "         4.6286e-38,  1.0721e-35,  6.8769e-37,  0.0000e+00,  0.0000e+00,\n",
      "         4.2882e-35,  4.6288e-38,  3.5032e-44,  0.0000e+00,  1.4235e-38,\n",
      "         2.3625e-34,  1.1473e-35,  0.0000e+00,  0.0000e+00,  7.4056e-37,\n",
      "         5.9135e-43,  5.9835e-43,  0.0000e+00,  4.7754e-38,  2.7508e-36,\n",
      "         0.0000e+00]), it has 1 dimensions, and is of shape torch.Size([76]), and has size: <built-in method size of Tensor object at 0x7f28508ba810>\n"
     ]
    }
   ],
   "source": [
    "#passing in a single number gives you a 0-dimensional tensor\n",
    "num = torch.Tensor(76)\n",
    "print(f'num is {num}, it has {num.dim()} dimensions, and is of shape {num.shape}, and has size: {num.size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f77bfca7-d72a-4ec9-9933-6cb5d1a8193d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Note the above use of `torch.Tensor` gives you a list of 76 random numbers.  The use of the capital T in tensor is the reason. See below for use of `torch.tensor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d141f3c-876e-4505-a2ba-947f05a80a07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 is a torch tensor of data type torch.int64\n",
      "num_1 has the following shape: torch.Size([])\n",
      "num_1 has the following dimensions: 0-d\n",
      "num_1 has the following size: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "num_1 = torch.tensor(74)\n",
    "print(f'{num_1} is a torch tensor of data type {num_1.dtype}\\n'\n",
    "      f'num_1 has the following shape: {num_1.shape}\\n'\n",
    "      f'num_1 has the following dimensions: {num_1.ndim}-d\\n'\n",
    "      f'num_1 has the following size: {num_1.size()}')\n",
    "\n",
    "\n",
    "#print(f'num_1 is {num_1}, it has shape {num_1.shape} \\nand is {num_1.dim()}-d and has size: {num_1.size()}')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b18dfa9-e645-4bb2-a96e-3071a14a242b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_1 is 24, it has 0 dimensions, and is of shape torch.Size([]), and has size: <built-in method size of Tensor object at 0x7f2816c76330>\n"
     ]
    }
   ],
   "source": [
    "num_1 = torch.tensor(24)\n",
    "print(f'num_1 is {num_1}, it has {num_1.dim()} dimensions, and is of shape {num_1.shape}, and has size: {num_1.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42e31fd3-0af5-43e1-8987-33ce8df1eaec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  2.0000, 99.0000, 42.3000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#passing in a vector or list gives you a one-dimension tensor as opposed to a 0-d tensor\n",
    "integer = torch.Tensor([1,2,99,42.3])\n",
    "integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d41e8aaf-410b-49fa-ba08-b73852df51a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer.shape == integer.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6773602a-2fe5-49a8-93ba-97d383de5d66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7450952b-5a73-4a82-8389-a77a6f7aba9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79a3585e-efef-4ae0-b94d-7af79b133e6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer.dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1959b2ce-12a7-4caf-8291-9265d780ca65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Using unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7c87d95-3fbf-4135-82bc-c5962ec0cb6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  2.0000, 99.0000, 42.3000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e2e3dc0-5074-41dc-a618-ff2f3166d3a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f2b6553-af1e-490e-a193-61f14a61f32e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  2.0000, 99.0000, 42.3000]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_1 =integer.unsqueeze(0)\n",
    "integer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df6d676b-d945-48ac-882f-25deed950228",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_1.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be9ea720-f4c1-4d89-a5ef-03fe5225ba5e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Added a new dimension - we now have a one-row, four-column tensor"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c29a20f2-a344-4554-9ad8-4dc74a34395d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_d_tensor:\n",
      "tensor([[1., 8., 9.],\n",
      "        [9., 3., 2.]])\n",
      "Shape is torch.Size([2, 3])\n",
      "Size is torch.Size([2, 3])\n",
      "Dimension is: 2\n"
     ]
    }
   ],
   "source": [
    "two_d_tensor = torch.Tensor([[1,8,9],[9,3,2]])\n",
    "print(f'two_d_tensor:\\n{two_d_tensor}\\nShape is {two_d_tensor.shape}\\nSize is {two_d_tensor.size()}\\nDimension is: {two_d_tensor.dim()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "896102c8-3749-4610-b972-d130ca46b51a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_d_tensor:\n",
      "tensor([[[1., 8., 9.],\n",
      "         [9., 3., 2.]]])\n",
      "Shape is torch.Size([1, 2, 3])\n",
      "Size istorch.Size([1, 2, 3])\n",
      "Dimension is: 3\n"
     ]
    }
   ],
   "source": [
    "#Use unsqueeze to add a batch size: we now have 1 batch containing 2 rows × 3 columns.\n",
    "two_d_tensor = two_d_tensor.unsqueeze(0)\n",
    "print(f'two_d_tensor:\\n{two_d_tensor}\\nShape is {two_d_tensor.shape}\\nSize is{two_d_tensor.size()}\\nDimension is: {two_d_tensor.dim()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6134f9b-2d0e-4ec4-9142-b648e4068558",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The unsqueeze function adds a dimension at the index we choose - so for example, by saying `.unsqueeze(0)`, we add a dimension at the 0th index (i.e. right at the beginning.)  The 0-index dimension (i.e. the first one), may typically be thought of as the batch size in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "757479e8-efbf-47e7-8ce2-97f19c5d2d2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`integer` is a 0-d Tensor: 1234\n",
      "`decimal` is a 0-d Tensor: 3.1415927410125732\n"
     ]
    }
   ],
   "source": [
    "integer = torch.tensor(1234)\n",
    "decimal = torch.tensor(3.14159265359)\n",
    "\n",
    "print(f\"`integer` is a {integer.ndim}-d Tensor: {integer}\")\n",
    "print(f\"`decimal` is a {decimal.ndim}-d Tensor: {decimal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c914e533-57ae-49a9-889e-ac4be3eb95ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'integer is 1234, has the shape of torch.Size([]), and has dimension 0.\n",
      "integer is a 0-d Tensor.\n"
     ]
    }
   ],
   "source": [
    "print(f\"'integer is {integer}, has the shape of {integer.shape}, and has dimension {integer.dim()}.\")\n",
    "print(f\"integer is a {integer.ndim}-d Tensor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c907e8f-5d91-4afb-a97c-8b36247e3596",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Vectors and lists can be used to create 1-d tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e044692b-01b4-40cb-9f16-4e0a85389572",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this gives you a list with 100 elements\n",
    "len(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de39e358-6306-452f-878c-1913b6fa3bf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`fibonacci` is a 1-d Tensor with shape: torch.Size([6])\n",
      "`count_to_100` is a 1-d Tensor with shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "fibonacci = torch.tensor([1, 1, 2, 3, 5, 8])\n",
    "count_to_100 = torch.tensor(range(100))\n",
    "\n",
    "print(f\"`fibonacci` is a {fibonacci.ndim}-d Tensor with shape: {fibonacci.shape}\")\n",
    "print(f\"`count_to_100` is a {count_to_100.ndim}-d Tensor with shape: {count_to_100.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba93a388-c752-48a4-b291-925c91cae085",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Creating 2-dimensional matrices\n",
    "Next, let’s create 2-d (i.e., matrices) and higher-rank tensors. In image processing and computer vision, we will use 4-d Tensors with dimensions corresponding to batch size, number of color channels, image height, and image width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad853ec2-85f8-4c73-babe-7ec826021344",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images is a 4-d Tensor with shape: torch.Size([10, 3, 256, 256])\n",
      "matrix is a 2-d Tensor with shape: torch.Size([2, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  9],\n",
       "        [ 2,  4,  9, 16]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Defining higher-order Tensors ###\n",
    "\n",
    "'''TODO: Define a 2-d Tensor'''\n",
    "matrix = torch.tensor([[1,2,3,9],[2,4,9,16]])\n",
    "\n",
    "assert isinstance(matrix, torch.Tensor), \"matrix must be a torch Tensor object\"\n",
    "assert matrix.ndim == 2\n",
    "\n",
    "'''TODO: Define a 4-d Tensor.'''\n",
    "# Use torch.zeros to initialize a 4-d Tensor of zeros with size 10 x 3 x 256 x 256.\n",
    "#   You can think of this as 10 images where each image is RGB 256 x 256.\n",
    "images = torch.zeros(10,3,256,256)\n",
    "\n",
    "assert isinstance(images, torch.Tensor), \"images must be a torch Tensor object\"\n",
    "assert images.ndim == 4, \"images must have 4 dimensions\"\n",
    "assert images.shape == (10, 3, 256, 256), \"images is incorrect shape\"\n",
    "print(f\"images is a {images.ndim}-d Tensor with shape: {images.shape}\")\n",
    "print(f\"matrix is a {matrix.ndim}-d Tensor with shape: {matrix.shape}\")\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0730a997-7417-487d-905a-b402acb31e9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30a14498-4ca3-49e3-b5bb-355f0ceb38de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The shape of a tensor provides the number of elements in each tensor dimension. The shape is quite useful, and we'll use it often. You can also use slicing to access subtensors within a higher-rank tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eb04142-62fc-4ea9-aba7-eb5ed34f38d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  9],\n",
       "        [ 2,  4,  9, 16]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5141abb0-42f9-4502-9a7e-723c341c5b3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  4,  9, 16])\n"
     ]
    }
   ],
   "source": [
    "row_vector = matrix[1]\n",
    "print(row_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21145f9a-bbde-43da-8bc4-4cde580f129f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "#getting a single element from the tensor\n",
    "single_element = matrix[0,2]\n",
    "print(single_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fd6b269-2f92-47e4-a6de-7620edea4f6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 9])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting a column from the tensor\n",
    "column_vector = matrix[:,2] #i.e., getting \"all rows\" and the second column\n",
    "column_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2a00033-6ab6-4206-aa63-0cb6bf3fbaea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row vector:tensor([ 2,  4,  9, 16])\n",
      "column vector: tensor([2, 4])\n",
      "matrix scalar: 3\n"
     ]
    }
   ],
   "source": [
    "#You can also use slicing to access subtensors within a higher-rank tensor:\n",
    "row_vector = matrix[1] #row number 1\n",
    "column_vector = matrix[:,1] #all rows, column number 1\n",
    "matrix_scalar = matrix[0,2] #the scalar at row 0, column 2\n",
    "print(f\"row vector:{row_vector}\")\n",
    "print(f\"column vector: {column_vector}\")\n",
    "print(f\"matrix scalar: {matrix_scalar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18cdbb42-1d1e-4d9c-8417-ef900784255b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#1.2 Computations on Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6f2477f-c4b3-45bc-830c-0ae95b568f27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A convenient way to think about and visualize computations in a machine learning framework like PyTorch is in terms of graphs. We can define this graph in terms of tensors, which hold data, and the mathematical operations that act on these tensors in some order. Let's look at a simple example, and define this computation using PyTorch:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c1bab72-de87-4033-8378-857fb9fa1b8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![Computational Graph](https://raw.githubusercontent.com/michaellevine00/mit_intro_to_deep_learning/main/images/computational_graph.png)\n",
    "\n",
    "\"computational_graph\"\n",
    "## Adding images in Databricks\n",
    "To add the above, I just added this in the markdown: `![Computational Graph](/files/tables/data/computational_graph.png)` - prior to doing so I uploaded the png into databricks by clicking New > upload data > upload data to DBFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68bc1c70-5893-464a-b511-66fcfed189ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1: 76. c1 is of type: torch.LongTensor and is of size torch.Size([])\n",
      "c2: 76. c2 is of type: torch.LongTensor and is of size torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "#Create the nodes in the graph and initialize values \n",
    "a = torch.tensor(15)\n",
    "b = torch.tensor (61)\n",
    "\n",
    "#add the terms to create new tensors\n",
    "c1 = torch.add(a,b)\n",
    "c2 = a + b  # PyTorch overrides the \"+\" operation so that it is able to act on Tensors\n",
    "print(f'c1: {c1}. c1 is of type: {c1.type()} and is of size {c1.size()}')\n",
    "print(f'c2: {c2}. c2 is of type: {c2.type()} and is of size {c2.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d210014-eb1a-4c8c-b51c-f235357b0c35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A slightly more complicated example\n",
    "\n",
    "![math_operation](https://raw.githubusercontent.com/michaellevine00/mit_intro_to_deep_learning/main/images/math_operation.png)\n",
    "\n",
    "\"math_operation.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0c5bff8-ecf9-456d-a792-23971e7bd22b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here, we take two inputs, a, b, and compute an output e. Each node in the graph represents an operation that takes some input, does some computation, and passes its output to another node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49eb89b1-ba35-4fa5-acef-3c40b43d7589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Defining Tensor Computations ###\n",
    "\n",
    "#Construct a simple computation function\n",
    "def func(a,b):\n",
    "    ''''TODO: Define the operation for c, d, e.'''''\n",
    "    c= a+b\n",
    "    d= b-1\n",
    "    e= c*d\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "426a9ef5-4dfa-4159-9810-db2ef664cb6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, we can call this function to execute the computation graph given some inputs a,b:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9efb4d0-11ae-4f10-b3ec-70d844c04869",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_out: 6.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = 1.5, 2.5\n",
    "e_out = func(a,b)\n",
    "print(f'e_out: {e_out}.')\n",
    "type(e_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c38e233c-6e97-4c06-a041-3d50ed971445",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Math notation - Latex\n",
    "For a linear layer:  \n",
    "$$ y = \\sigma(Wx + b) $$  \n",
    "where  \n",
    "- $ W \\in \\mathbb{R}^{d_{\\text{out}} \\times d_{\\text{in}}} $ is the weight matrix  \n",
    "- $ x \\in \\mathbb{R}^{d_{\\text{in}}} $ is the input vector  \n",
    "- $ b \\in \\mathbb{R}^{d_{\\text{out}}} $ is the bias vector  \n",
    "- $ \\sigma(\\cdot) $ is the activation function (e.g., ReLU, tanh, etc.)\n",
    "\n",
    "We can also write it more compactly as  \n",
    "$$ y = \\sigma(Wx + b) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db40768b-5545-4495-abfa-7ed89a3e71b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1.3 Neural Networks in PyTorch\n",
    "We can also define neural networks in PyTorch. PyTorch uses torch.nn.Module, which serves as a base class for all neural network modules in PyTorch and thus provides a framework for building and training neural networks.\n",
    "\n",
    "Let's consider the example of a simple perceptron defined by just one dense (aka fully-connected or linear) layer:$$y = \\sigma(Wx + b)$$ where $$W$$ represents a matrix of weights, $$b$$ is a bias, $$x$$ is the input, $$\\sigma$$ is the activation function, and $$y$$ is the output.\n",
    "\n",
    "![neural_network_sigmoid_activation](https://raw.githubusercontent.com/michaellevine00/mit_intro_to_deep_learning/main/images/neural_network_sigmoid_activation.png)\n",
    "\n",
    "We will use `torch.nn.Module` to define layers -- the building blocks of neural networks. Layers implement common neural networks operations. In PyTorch, when we implement a layer, we subclass `nn.Module` and define the parameters of the layer as attributes of our new class. We also define and override a function `forward`, which will define the forward pass computation that is performed at every step. All classes subclassing `nn.Module` should override the forward function.\n",
    "\n",
    "Let's write a dense layer class to implement a perceptron defined above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db7f1960-fb56-4f51-b672-c38710d9ef59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Defining a dense layer ###\n",
    "\n",
    "# num_inputs: number of input nodes\n",
    "# num_outputs: number of output nodes\n",
    "# x: input to the layer\n",
    "\n",
    "class OurDenseLayer(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(OurDenseLayer, self).__init__()\n",
    "        # Define and initialize parameters: a weight matrix W and bias b\n",
    "        # Note that the parameter initialize is random!\n",
    "        self.W = torch.nn.Parameter(torch.randn(num_inputs, num_outputs))\n",
    "        self.bias = torch.nn.Parameter(torch.randn(num_outputs))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''TODO: define the operation for z (hint: use torch.matmul).'''\n",
    "        z = torch.matmul(x,self.W)+self.bias\n",
    "\n",
    "        '''TODO: define the operation for out (hint: use torch.sigmoid).'''\n",
    "        y = torch.sigmoid(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a0adfcd-e081-46e9-a528-6215e60b7b27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Defining a dense layer ###\n",
    "\n",
    "# num_inputs: number of input nodes\n",
    "# num_outputs: number of output nodes\n",
    "# x: input to the layer\n",
    "\n",
    "class OurDenseLayer(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(OurDenseLayer, self).__init__()\n",
    "        # Define and initialize parameters: a weight matrix W and bias b\n",
    "        # Note that the parameter initialize is random!\n",
    "        self.W = torch.nn.Parameter(torch.randn(num_inputs, num_outputs))\n",
    "        self.bias = torch.nn.Parameter(torch.randn(num_outputs))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''TODO: define the operation for z (hint: use torch.matmul).'''\n",
    "        z = torch.matmul(x,self.W)+self.bias\n",
    "\n",
    "        '''TODO: define the operation for out (hint: use torch.sigmoid).'''\n",
    "        y = torch.sigmoid(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "909a7bbb-74a9-4da6-b5db-a4106f165280",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of rand_num: torch.Size([2, 4, 3, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4433, -0.3157, -0.0253,  0.0615,  0.2681, -1.9439, -1.5134],\n",
       "          [ 0.5198, -1.1448,  0.6331,  0.3692, -0.3164, -1.0006,  0.2223],\n",
       "          [-0.5676,  2.2107,  0.6146, -0.9115, -0.2115,  0.3972, -0.4228]],\n",
       "\n",
       "         [[ 1.1905, -0.9105,  1.3880,  0.2813,  0.7428,  0.0605, -0.6952],\n",
       "          [-0.4152,  0.7824,  0.3718,  1.6486, -0.2518,  0.8194, -2.2059],\n",
       "          [ 1.1276,  0.4035,  1.1075, -0.6207, -1.7927,  0.3005, -0.0719]],\n",
       "\n",
       "         [[-0.4334, -0.4440,  0.0081,  0.4319, -0.4454, -0.4123,  1.3321],\n",
       "          [-1.5695,  0.5450, -1.6057,  0.0911,  1.0655, -0.4435, -0.3389],\n",
       "          [-0.8114, -2.2463, -0.3694,  0.0245,  0.6396, -0.2188, -1.1950]],\n",
       "\n",
       "         [[-0.5981, -0.4013,  0.3619,  0.2992,  0.7335, -0.1032, -0.4479],\n",
       "          [ 0.0927, -1.1998, -0.0579, -0.1270, -1.0262, -1.1647,  1.1661],\n",
       "          [-1.3425,  0.9142, -0.1464, -0.9816,  2.2514,  0.8341,  1.4661]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0344, -1.0010,  0.1127, -1.4099, -1.3201, -1.0933,  0.8420],\n",
       "          [-1.4250, -0.9591,  0.0473, -0.9805,  2.0545, -1.8030,  1.1080],\n",
       "          [ 1.8230,  0.1028,  0.0947, -0.3862,  0.0946, -0.3154, -0.8924]],\n",
       "\n",
       "         [[-0.5600,  0.2246,  1.2787, -0.5875, -1.3382, -1.7391,  0.6823],\n",
       "          [ 0.4664,  0.5862, -0.6794,  0.3950,  2.2181,  1.5825,  1.5515],\n",
       "          [ 0.5542,  2.0288,  0.6004,  0.5370,  0.1217,  1.3323,  0.1854]],\n",
       "\n",
       "         [[ 0.7906,  0.3920, -0.2294,  0.0168,  0.5002, -0.6568, -0.3324],\n",
       "          [-0.4287, -1.8224, -1.6545,  0.2331, -0.3782, -0.1093,  2.0071],\n",
       "          [-0.1218, -1.4506,  0.4942,  0.2281, -0.9058,  0.8774, -1.9817]],\n",
       "\n",
       "         [[ 1.1541,  0.3622,  1.7495, -0.1339, -1.0639,  0.7245,  0.1818],\n",
       "          [ 0.7280,  1.9887,  0.5748,  2.0123,  0.4549,  1.2617, -1.2351],\n",
       "          [ 0.4197,  0.5057, -1.3454,  1.4652,  1.0057,  2.4387,  1.7358]]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_num = torch.randn(2,4,3,7)\n",
    "print(f\"shape of rand_num: {rand_num.shape}\")\n",
    "rand_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f2b721e1-3c3c-49d7-afef-f8dc8fef6ade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "randn(*size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
      "\n",
      "\n",
      "Returns a tensor filled with random numbers from a normal distribution\n",
      "with mean `0` and variance `1` (also called the standard normal\n",
      "distribution).\n",
      "\n",
      ".. math::\n",
      "    \\text{out}_{i} \\sim \\mathcal{N}(0, 1)\n",
      "\n",
      "For complex dtypes, the tensor is i.i.d. sampled from a `complex normal distribution`_ with zero mean and\n",
      "unit variance as\n",
      "\n",
      ".. math::\n",
      "    \\text{out}_{i} \\sim \\mathcal{CN}(0, 1)\n",
      "\n",
      "This is equivalent to separately sampling the real :math:`(\\operatorname{Re})` and imaginary\n",
      ":math:`(\\operatorname{Im})` part of :math:`\\text{out}_i` as\n",
      "\n",
      ".. math::\n",
      "    \\operatorname{Re}(\\text{out}_{i}) \\sim \\mathcal{N}(0, \\frac{1}{2}),\\quad\n",
      "    \\operatorname{Im}(\\text{out}_{i}) \\sim \\mathcal{N}(0, \\frac{1}{2})\n",
      "\n",
      "The shape of the tensor is defined by the variable argument :attr:`size`.\n",
      "\n",
      "\n",
      "Args:\n",
      "    size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "        Can be a variable number of arguments or a collection like a list or tuple.\n",
      "\n",
      "Keyword args:\n",
      "    generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
      "    out (Tensor, optional): the output tensor.\n",
      "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "        Default: if ``None``, uses a global default (see :func:`torch.set_default_dtype`).\n",
      "    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "        Default: ``torch.strided``.\n",
      "    device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "        Default: if ``None``, uses the current device for the default tensor type\n",
      "        (see :func:`torch.set_default_device`). :attr:`device` will be the CPU\n",
      "        for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "    requires_grad (bool, optional): If autograd should record operations on the\n",
      "        returned tensor. Default: ``False``.\n",
      "    pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
      "        the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> torch.randn(4)\n",
      "    tensor([-2.1436,  0.9966,  2.3426, -0.6366])\n",
      "    >>> torch.randn(2, 3)\n",
      "    tensor([[ 1.5954,  2.8929, -1.0923],\n",
      "            [ 1.1719, -0.4709, -0.1996]])\n",
      "\n",
      ".. _complex normal distribution: https://en.wikipedia.org/wiki/Complex_normal_distribution\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "torch.randn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75e777b7-5446-4f67-823e-d3b36fbef8f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, let's test the output of our layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f283eb9e-95e3-4a04-8745-2ce213e7510b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 2])\n",
      "output shape: torch.Size([1, 3])\n",
      "output result: tensor([[0.0014, 0.6433, 0.0666]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a layer and test the output!\n",
    "num_inputs = 2\n",
    "num_outputs = 3\n",
    "layer = OurDenseLayer(num_inputs, num_outputs)\n",
    "x_input = torch.tensor([[1, 5.]])\n",
    "y = layer(x_input)\n",
    "\n",
    "print(f\"input shape: {x_input.shape}\")\n",
    "print(f\"output shape: {y.shape}\")\n",
    "print(f\"output result: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d5db73e-9ba6-4d2e-b314-6c0e3f62f5de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Conveniently, PyTorch has defined a number of `nn.Modules` (or Layers) that are commonly used in neural networks, for example a `nn.Linear` or `nn.Sigmoid` module.\n",
    "\n",
    "Now, instead of using a single `Module` to define our simple neural network, we'll use the `nn.Sequential` module from PyTorch and a single `nn.Linear` layer to define our network. With the `Sequential` API, you can readily create neural networks by stacking together layers like building blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46e22d8a-f1e3-48ee-858b-f56be4ad79ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Defining a neural network using the PyTorch Sequential API ###\n",
    "\n",
    "# define the number of inputs and outputs\n",
    "n_input_nodes = 2\n",
    "n_output_nodes = 3\n",
    "\n",
    "# Define the model\n",
    "'''TODO: Use the Sequential API to define a neural network with a\n",
    "    single linear (dense!) layer, followed by non-linearity to compute z'''\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_input_nodes, n_output_nodes),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3d3a9fa-0928-4ec5-b2c8-de7e7c012128",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We've defined our model using the Sequential API. Now, we can test it out using an example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0653fee-f7fe-404c-a998-02e18415f704",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 2])\n",
      "output shape: torch.Size([1, 3])\n",
      "output result: tensor([[0.0014, 0.6433, 0.0666]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test the model with example input\n",
    "x_input = torch.tensor([[1, 7.]])\n",
    "model_output = model(x_input)\n",
    "print(f\"input shape: {x_input.shape}\")\n",
    "print(f\"output shape: {y.shape}\")\n",
    "print(f\"output result: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18088550-6271-46bc-8c97-57c21fd8c9fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Continue here\n",
    "With PyTorch, we can create more flexible models by subclassing `nn.Module`. The `nn.Module` class allows us to group layers together flexibly to define new architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0d2cfcc-2a94-45ea-93a8-9963f01b49e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "intro_deep_learning_lab_1_pt_1_2025_10_31",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
